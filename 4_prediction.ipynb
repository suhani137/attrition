{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PREDICTIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Class Imbalance SMOTE\n",
    "value , counts = np.unique(y, return_counts=True)\n",
    "dict(zip(value, counts))\n",
    "\n",
    "from imblearn.over_sampling import SMOTE\n",
    "os = SMOTE(sampling_strategy='auto', random_state=100, k_neighbors=5)\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "smote_X,smote_y=os.fit_sample(X, y)\n",
    "columns=X.columns\n",
    "smote_X = pd.DataFrame(data=smote_X,columns=columns)\n",
    "smote_y= pd.DataFrame(data=smote_y,columns=['y'])\n",
    "\n",
    "print(\"length of oversampled data is \",len(smote_X))\n",
    "print(\"Number of no subscription in oversampled data\",len(smote_y[smote_y['y']==0]))\n",
    "print(\"Number of subscription\",len(smote_y[smote_y['y']==1]))\n",
    "print(\"Proportion of no subscription data in oversampled data is \",len(smote_y[smote_y['y']==0])/len(smote_X))\n",
    "print(\"Proportion of subscription data in oversampled data is \",len(smote_y[smote_y['y']==1])/len(smote_X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Selecting significant columns\n",
    "cols = ['EnvironmentSatisfaction_Low','EnvironmentSatisfaction_Very High',\n",
    "       'Gender_Male','JobInvolvement_Low','JobInvolvement_Medium','JobInvolvement_Very High',\n",
    "       'JobRole_Laboratory Technician','JobRole_Research Scientist','JobRole_Sales Executive','JobRole_Sales Representative',\n",
    "       'JobSatisfaction_Low','JobSatisfaction_Very High','OverTime_Yes','RelationshipSatisfaction_Low',\n",
    "        'RelationshipSatisfaction_Medium','RelationshipSatisfaction_Very High','WorkLifeBalance_Bad','WorkLifeBalance_Best',\n",
    "       'WorkLifeBalance_Good','DailyRate','DistanceFromHome','MonthlyRate','StockOptionLevel','TrainingTimesLastYear',\n",
    "       'YearsInCurrentRole','YearsSinceLastPromotion']\n",
    "X=smote_X[cols]\n",
    "y=smote_y['y']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Logistic Regression with R-square\n",
    "import statsmodels.api as sm\n",
    "logit_model=sm.Logit(y,X)\n",
    "result=logit_model.fit()\n",
    "print(result.summary2())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train-test split\n",
    "from sklearn.model_selection import train_test_split\n",
    "train_X, val_X, train_y, val_y = train_test_split(X,y,train_size=0.8, \n",
    "                                                    test_size=0.2,random_state=50)\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Logit with confusion matrix\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "model1 = LogisticRegression()\n",
    "model1.fit(train_X, train_y)\n",
    "predicted = model1.predict(val_X)\n",
    "\n",
    "print(\"Accuracy : \"+ str(accuracy_score(predicted, val_y)))\n",
    "print(\"Precision : \"+str(precision_score(predicted, val_y)))\n",
    "print(\"Recall : \"+str(recall_score(predicted, val_y)))\n",
    "print(\"F1-Score : \"+str(f1_score(predicted, val_y)))\n",
    "print(\"Confusion Matrix :\")\n",
    "print(confusion_matrix(predicted, val_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Naive Bayes\n",
    "from sklearn.naive_bayes import BernoulliNB \n",
    "\n",
    "model2 = BernoulliNB ()\n",
    "model2.fit(train_X, train_y)\n",
    "predicted = model2.predict(val_X)\n",
    "\n",
    "print(\"Accuracy : \"+ str(accuracy_score(predicted, val_y)))\n",
    "print(\"Precision : \"+str(precision_score(predicted, val_y)))\n",
    "print(\"Recall : \"+str(recall_score(predicted, val_y)))\n",
    "print(\"F1-Score : \"+str(f1_score(predicted, val_y)))\n",
    "print(\"Confusion Matrix :\")\n",
    "print(confusion_matrix(predicted, val_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Decision Tree\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn import tree\n",
    "\n",
    "model3 = DecisionTreeClassifier(criterion = \"gini\",min_samples_leaf=10)\n",
    "model3.fit(train_X, train_y)\n",
    "predicted = model3.predict(val_X)\n",
    "print(\"Accuracy : \"+ str(accuracy_score(predicted, val_y)))\n",
    "print(\"Precision : \"+str(precision_score(predicted, val_y)))\n",
    "print(\"Recall : \"+str(recall_score(predicted, val_y)))\n",
    "print(\"F1-Score : \"+str(f1_score(predicted, val_y)))\n",
    "print(\"Confusion Matrix :\")\n",
    "print(confusion_matrix(predicted, val_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Random Forest\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "forest_model = RandomForestClassifier()\n",
    "forest_model.fit(train_X, train_y)\n",
    "predicted = forest_model.predict(val_X)\n",
    "print(\"Accuracy : \"+ str(accuracy_score(predicted, val_y)))\n",
    "print(\"Precision : \"+str(precision_score(predicted, val_y)))\n",
    "print(\"Recall : \"+str(recall_score(predicted, val_y)))\n",
    "print(\"F1-Score : \"+str(f1_score(predicted, val_y)))\n",
    "print(\"Confusion Matrix :\")\n",
    "print(confusion_matrix(predicted, val_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Variable Importance for mdoel with highest accuracy\n",
    "import operator\n",
    "imp_dict = { X.columns[i]:imp for i,imp in enumerate(forest_model.feature_importances_)}\n",
    "sorted_imp_dict = sorted(imp_dict.items(), key=operator.itemgetter(1), reverse=True)\n",
    "sorted_imp_dict"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
